{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "# clear punctuation\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "\n",
    "path = \"WMT14/English-German/\"\n",
    "\n",
    "f = open(path + 'train.en', 'r')\n",
    "en_sentences = []\n",
    "\n",
    "for line in f:\n",
    "    current = \" \".join(\"\" if i in punctuation else i for i in line.lower().split())\n",
    "    en_sentences.append(current.split())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count appearances\n",
    "en_current = np.hstack(en_sentences)\n",
    "en_unq, en_cnt = np.unique(en_current, return_counts=True)\n",
    "en = {}\n",
    "for i in range(len(en_unq)):\n",
    "    en[en_unq[i]] = en_cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d2940f743f499797047ecd8e3259e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3961179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# preprocess sentences with <start>, <end> and <unk>\n",
    "min_count = 5\n",
    "en_sentences_prep = []\n",
    "for i in tqdm_notebook(range(len(en_sentences))):\n",
    "    current = en_sentences[i]\n",
    "    current = \" \".join(\"<unk>\" if en[i] < min_count else i for i in current)\n",
    "    current = '<start> ' + current + ' <end>'\n",
    "    en_sentences_prep.append(current.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3961179, 3961179, 0.01411177137677382)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_sentences), len(en_sentences_prep), np.sum(en_cnt[en_cnt < min_count]) / np.sum(en_cnt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to _prep file\n",
    "f = open(path + 'train_prep.en', 'w')\n",
    "for i in range(len(en_sentences_prep)):\n",
    "    current = en_sentences_prep[i]\n",
    "    print(str(len(current)) + ' ' + \" \".join(current), file=f)\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(line, lang, min_count):\n",
    "    current = \" \".join(\"\" if i in punctuation else i for i in line.lower().split())\n",
    "    current = current.split()\n",
    "    leng = len(current) + 2\n",
    "    st = len(\"\".join(\" \" if (i not in lang.keys() or lang[i] < min_count) else \"\" for i in current))\n",
    "    current = \" \".join(\"<unk>\" if (i not in lang.keys() or lang[i] < min_count) else i for i in current)\n",
    "    current = '<start> ' + current + ' <end>'\n",
    "    return leng, st, current\n",
    "\n",
    "def preprocess_file(file, lang, min_count):\n",
    "    f_in = open(file, 'r')\n",
    "    curr = file.split('.')\n",
    "    f_out = open(curr[0] + '_prep.' + curr[1], 'w')\n",
    "    # to know <unk> ratio\n",
    "    lleng, sst = 0, 0\n",
    "    \n",
    "    for line in f_in:\n",
    "        leng, st, current = preprocess(line, lang, min_count)\n",
    "        lleng += leng\n",
    "        sst += st\n",
    "        print(str(leng) + ' ' + current, file=f_out)\n",
    "    \n",
    "    f_in.close()\n",
    "    f_out.close()\n",
    "    return sst, lleng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016778899860474924"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st, leng = preprocess_file(path + 'valid.en', en, min_count)\n",
    "st / leng * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01931894286744629"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st, leng = preprocess_file(path + 'test.en', en, min_count)\n",
    "st / leng * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deutsch\n",
    "# clear punctuation\n",
    "f = open(path + 'train.de', 'r')\n",
    "de_sentences = []\n",
    "\n",
    "for line in f:\n",
    "    current = \" \".join(\"\" if i in punctuation else i for i in line.lower().split())\n",
    "    de_sentences.append(current.split())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count appearances\n",
    "de_current = np.hstack(de_sentences)\n",
    "de_unq, de_cnt = np.unique(de_current, return_counts=True)\n",
    "de = {}\n",
    "for i in range(len(de_unq)):\n",
    "    de[de_unq[i]] = de_cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986bba65d8a9452799314670c5fad1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3961179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocess sentences with <start>, <end> and <unk>    \n",
    "de_sentences_prep = []\n",
    "for i in tqdm_notebook(range(len(de_sentences))):\n",
    "    current = de_sentences[i]\n",
    "    current = \" \".join(\"<unk>\" if de[i] < min_count else i for i in current)\n",
    "    current = '<start> ' + current + ' <end>'\n",
    "    de_sentences_prep.append(current.split())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3961179, 3961179, 0.0064189704799666675)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_sentences), len(de_sentences_prep), np.sum(de_cnt[de_cnt < min_count]) / np.sum(de_cnt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path + 'train_prep.de', 'w')\n",
    "for i in range(len(de_sentences_prep)):\n",
    "    current = de_sentences_prep[i]\n",
    "    print(str(len(current)) + ' ' + \" \".join(current), file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00672508643063383"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st, leng = preprocess_file(path + 'valid.de', de, min_count)\n",
    "st / leng * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9535634467345419"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st, leng = preprocess_file(path + 'test.de', de, min_count)\n",
    "st / leng * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained embeddings\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path + 'train_prep.en', 'r')\n",
    "en_sentences = []\n",
    "for line in f:\n",
    "    current = line.split()[1:]\n",
    "    en_sentences.append(current)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3961179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count, dmodel = 5, 256\n",
    "en_model = Word2Vec(sentences=en_sentences, size=dmodel, min_count=min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model.save(path + \"word2vec_en\" + str(dmodel) + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(path + 'train_prep.de', 'r')\n",
    "de_sentences = []\n",
    "for line in f:\n",
    "    current = line.split()[1:]\n",
    "    de_sentences.append(current)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3961179"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_model = Word2Vec(sentences=de_sentences, size=dmodel, min_count=min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_model.save(path + \"word2vec_de\" + str(dmodel) + \".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31797, 26034)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_model.wv.vocab.keys()), len(en_model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
